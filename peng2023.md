#  Syllable Discovery and Cross-Lingual Generalization in a Visually Grounded, Self-Supervised Speech Model

Peng, P., Li, S.-W., Räsänen, O., Mohamed, A., Harwath, D. (2023) Syllable Discovery and Cross-Lingual Generalization in a Visually Grounded, Self-Supervised Speech Model. Proc. Interspeech 2023, 391-395, doi: 10.21437/Interspeech.2023-2044

pengSyllableDiscoveryCrossLingual2023

https://www.isca-archive.org/interspeech_2023/peng23e_interspeech.pdf

# Models
Hubert, VG-Hubert,

# Data
English: SpokenCOCO, Montreal Forced Aligned.
ALso Estonian and ZeroSpeech: Mandarin, English, French, German, Wolof.


# Method
Look at segmentation starting with feature self-similarity matrix (featSSM), normalized so it is all non-negative.  
Then, min-cut algorithm, separating all speech frames in sets with maiximal similarity within set and minimizing similarity between sets.
These sets/segments are then clustered based on their mean representations, first large number of clusters with KMeans, then agglomerate clustering to merge similar clusters.

## Train
On SpokenCOCO
## Evaluation syllable segmentation
Segmentation: precision, recall, F1, R. Tolerance 50, or 30 ms for ZeroSpeech.
Only on multisyllabic words.

# Results

## When in training
